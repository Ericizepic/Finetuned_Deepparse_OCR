{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import ast\n",
    "import re\n",
    "import string\n",
    "from copy import deepcopy\n",
    "from faker import Faker\n",
    "\n",
    "from numpy.random import choice\n",
    "from numpy.testing import assert_almost_equal, assert_equal\n",
    "from string import ascii_lowercase, digits\n",
    "from addr_term_dict import province_lst, cols, street_type, to_non_stand_num_term, to_non_stand_street_type, to_non_stand_street_dir, to_non_stand_prov, to_std, to_stand_street_type, to_stand_street_dir, to_non_std, street_dir\n",
    "\n",
    "\n",
    "fake_en = Faker(\"en_CA\")\n",
    "fake_fr = Faker(\"fr_CA\")\n",
    "\n",
    "aug_split = naw.SplitAug(min_char=3)\n",
    "\n",
    "deepparse_tags = [\n",
    "    \"Unit\",\n",
    "    \"StreetNumber\",\n",
    "    \"StreetName\",\n",
    "    \"Municipality\",\n",
    "    \"Province\",\n",
    "    \"PostalCode\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alley', 'alwy', 'anx', 'arc', 'ave', 'bayou', 'bch', 'bldg', 'blf', 'blfs', 'blk', 'blvd', 'bnd', 'bnglw', 'bot', 'br', 'brg', 'brgs', 'brk', 'brks', 'bsmt', 'byps', 'cabin', 'circ', 'clf', 'clfs', 'cmn', 'cmns', 'cmp', 'cnyn', 'cor', 'cors', 'cpe', 'cresc', 'crk', 'crossing', 'crossroad', 'cswy', 'ct', 'ctyd', 'ctr', 'curv', 'cv', 'cvs', 'dl', 'dm', 'div', 'dr', 'drs', 'dupl', 'dvwy', 'est', 'ests', 'exp', 'fcty', 'fl', 'fld', 'flds', 'fls', 'flt', 'frd', 'frds', 'frg', 'frgs', 'frk', 'frst', 'fry', 'fwy', 'gdfl', 'gpo', 'grdn', 'grn', 'grns', 'grv', 'grvs', 'gym', 'hbr', 'hbrs', 'hl', 'hls', 'hllw', 'hotl', 'hs', 'hsp', 'hts', 'hvn', 'hwy', 'jct', 'jcts', 'ky', 'kys', 'knl', 'knls', 'lck', 'lcks', 'ldg', 'lgt', 'lk', 'lks', 'ln', 'lp', 'lwr', 'mdw', 'mdws', 'ml', 'mls', 'mnr', 'mnrs', 'msn', 'mt', 'mtn', 'mtns', 'mtwy', 'nck', 'orch', 'ovl', 'ovlk', 'opas', 'pkwy', 'pl', 'plz', 'prk', 'prt', 'psge', 'pt', 'pts', 'pth', 'pthwy', 'rd', 'rds', 'rdg', 'rnch', 'rte', 'rvr', 'skwy', 'smt', 'spg', 'spgs', 'sq', 'st', 'stn', 'tce', 'tpke', 'trfy', 'trl', 'trwy', 'twr', 'u', 'un', 'upas', 'upr', 'vdct', 'vis', 'vl', 'vlg', 'vly', 'vlys', 'wl', 'wy'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_non_stand_street_type.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurace_prefix = [\n",
    "    \"in the following  property\",\n",
    "    \"location\",\n",
    "    \"property located at\",\n",
    "    \"insurace at location\",\n",
    "    \"premises\",\n",
    "    \"address\",\n",
    "    \"location\",\n",
    "    \"premises\",\n",
    "    \"address\",\n",
    "    \"location\",\n",
    "    \"premises\",\n",
    "    \"address\",\n",
    "    \"location\",\n",
    "    \"at\" ,\n",
    "    \"property\",\n",
    "    \"property\",\n",
    "    \"property\",\n",
    "    \"within the specified property\",\n",
    "    \"property situated at\",\n",
    "    \"insurance coverage for the location\",\n",
    "    \"property residing at\",\n",
    "    \"within this property\",\n",
    "    \"situated property at\",\n",
    "    \"insurance for this location\",\n",
    "    \"insurace at\",\n",
    "    \"postal address\",\n",
    "    \"mailing address\",\n",
    "    \"risk_details\",\n",
    "]\n",
    "\n",
    "insurace_suffix = [\n",
    "    \"your stated interest in this property has been removed\",\n",
    "    \"has been removed from this policy along with your name\",\n",
    "    \"your interest have been deleted from the policy effective\",\n",
    "    \"your stated interest in this property has been removed\",\n",
    "    \"has been removed from this policy along with your name\",\n",
    "    \"we are therefore removing you\",\n",
    "    \"your expressed interest in this property has been revoked\",\n",
    "    \"your inclusion in this policy, along with your name, has been omitted\",\n",
    "    \"your interests have been expunged from the policy, effective immediately\",\n",
    "    \"your specified interest in this property has been eliminated\",\n",
    "]\n",
    "\n",
    "insurace_suffix_fr = [\n",
    "    \"votre interet designe dans cette propriete a ete retire\",\n",
    "    \"votre intérêt déclaré pour cette propriété a été supprimé\",\n",
    "    \"votre intérêt déclaré pour cette propriété a été supprimé\",\n",
    "    \"votre nom a été retiré de cette police ainsi que votre intérêt\",\n",
    "    \"votre intérêt a été supprimé de la police à partir de\",\n",
    "    \"votre intérêt déclaré pour cette propriété a été supprimé\",\n",
    "    \"votre nom a été retiré de cette police ainsi que votre nom\",\n",
    "    \"nous vous retirons donc\",\n",
    "    \"votre intérêt exprimé pour cette propriété a été révoqué\",\n",
    "    \"votre inclusion dans cette police, ainsi que votre nom, a été omise\",\n",
    "    \"vos intérêts ont été effacés de la police, avec effet immédiat\",\n",
    "    \"votre intérêt spécifié pour cette propriété a été éliminé\"\n",
    "]\n",
    "\n",
    "insurace_prefix_fr = [\n",
    "    \"à la propriété suivante\",\n",
    "    \"emplacement\",\n",
    "    \"propriété située à\",\n",
    "    \"assurance à l'emplacement\",\n",
    "    \"locaux\",\n",
    "    \"adresse\",\n",
    "    \"à\",\n",
    "    \"au\",\n",
    "    \"propriété\",\n",
    "    \"au sein de la propriété spécifiée\",\n",
    "    \"propriété située à\",\n",
    "    \"couverture d'assurance pour l'emplacement\",\n",
    "    \"propriété résidant à\",\n",
    "    \"au sein de cette propriété\",\n",
    "    \"propriété située à\",\n",
    "    \"assurance pour cet emplacement\",\n",
    "    \"assurance à\",\n",
    "    \"adresse postale\",\n",
    "    \"adresse postale\",\n",
    "    \"détails du risque\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = pd.read_csv(\"ocr_confusion_matrix.csv\", index_col=0)\n",
    "conf_matrix_num_to_letter = pd.read_csv(\"ocr_confusion_matrix_num_to_letter.csv\", index_col=0) #confusion matrix that does not map number to letter\n",
    "assert_almost_equal(np.sum(conf_matrix, axis=1), np.ones(conf_matrix.shape[0]))\n",
    "\n",
    "def prob(p: float) -> bool:\n",
    "    return rand.uniform(0, 1) < p\n",
    "\n",
    "def pc_augment(s : str, letter_aug = 0.85, num_aug = 0.98, keep_p = 1) -> str:  \n",
    "    return \"\".join([c if c not in conf_matrix_num_to_letter.columns or (c != '0' and ((c.isdigit() and prob(num_aug)) or (not c.isdigit() and prob(letter_aug)))) else rand.choices(conf_matrix_num_to_letter.columns, weights=conf_matrix_num_to_letter.loc[c], k = 1)[0] for c in s if prob(keep_p)])\n",
    "\n",
    "def num_augment(s : str, letter_aug = 0.98, num_aug = 0.97, keep_p = 1) -> str:  \n",
    "    return \"\".join([c if c not in conf_matrix_num_to_letter.columns or (c.isdigit() and prob(num_aug)) or (not c.isdigit() and prob(letter_aug)) else rand.choices(conf_matrix_num_to_letter.columns, weights=conf_matrix_num_to_letter.loc[c], k = 1)[0] for c in s if prob(keep_p)])\n",
    "\n",
    "def rm_space_augment(s : str, keep_ws_p = 0.9):\n",
    "    return \"\".join([w for w in s if w not in string.whitespace or prob(keep_ws_p)])\n",
    "\n",
    "def augment(s : str, letter_aug = 0.85, num_aug = 0.98, keep_p = 1) -> str:  \n",
    "    return \"\".join([c if c not in conf_matrix.columns or (c.isdigit() and prob(num_aug) or (not c.isdigit() and prob(letter_aug))) else choice(conf_matrix.columns, p=conf_matrix.loc[c]) for c in s if prob(keep_p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'elif' statement on line 59 (1165887534.py, line 61)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 61\u001b[1;36m\u001b[0m\n\u001b[1;33m    elif (tags[i] == \"unit\" or tags[i] ==\"pobox\" or tags[i]==\"street_no\" and prob(0.03)):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'elif' statement on line 59\n"
     ]
    }
   ],
   "source": [
    "SUFFIXES = {1: \"st\", 2: \"nd\", 3: \"rd\"}\n",
    "\n",
    "def rand_ordinal_street():\n",
    "    num = rand.randint(1, 120)\n",
    "    suffix = \"th\" if 10 <= num % 100 <= 20 else SUFFIXES.get(num % 10, \"th\")\n",
    "    if prob(0.3):\n",
    "        return str(num)\n",
    "    \n",
    "    return str(num) + suffix\n",
    "\n",
    "def rand_unit_num():\n",
    "    options = [f\"{rand.randint(1, 120)}\", f\"{rand.randint(1, 9999)}\", f\"{rand.randint(1, 9999)}{rand.choice(ascii_lowercase)}\"] \n",
    "    return choice(options, p=[0.5, 0.35, 0.15])\n",
    "\n",
    "def rand_rr():\n",
    "    rroptions = [f\"rr {rand.randint(1, 120)}\", f\"rr{rand.randint(1, 120)}\"]\n",
    "    return rand.choice(rroptions)\n",
    "\n",
    "def insert_spaces(s, p):\n",
    "    s = list(s)\n",
    "    for i in range(len(s)-1):\n",
    "        if prob(p):\n",
    "            s[i] = s[i] + ' '\n",
    "    return ''.join(s)\n",
    "\n",
    "# def rand_gibberish_address(is_en = True):\n",
    "#     street = fake_en.street_address() if is_en else fake_fr.street_address()\n",
    "#     street_sec = fake_en.secondary_address() if is_en else fake_fr.secondary_address()\n",
    "#     base_addr = rand.choice([street, street_sec, street+street_sec, street_sec+street])\n",
    "#     gibberish_addr = augment(base_addr, letter_aug=0, num_aug=0, keep_p=0.85).lower()\n",
    "#     p = 0.85 \n",
    "#     if len(gibberish_addr.replace(\" \", \"\")) < 20: p = 0.5\n",
    "#     if len(gibberish_addr.replace(\" \", \"\")) < 10: p = 0.3\n",
    "#     gibberish_addr =  \"\".join([w if prob(p) else rand.choice(ascii_lowercase + digits + \"-\") for w in gibberish_addr])\n",
    "#     return \" \".join([w for w in gibberish_addr.split() if not w.isdigit() and len(w) > 3])\n",
    "\n",
    "\n",
    "def get_insertion_index(tags, exclude=None):\n",
    "    insertable_indices = [0, len(tags)]\n",
    "    for i in range(1, len(tags)):\n",
    "        if tags[i][:5] != tags[i - 1][:5]:\n",
    "            insertable_indices.append(i)\n",
    "\n",
    "    if exclude != None and exclude in insertable_indices:\n",
    "        insertable_indices.remove(exclude)\n",
    "    \n",
    "    assert len(insertable_indices) > 0\n",
    "    return rand.choice(insertable_indices)\n",
    "\n",
    "def aug_words_tags(words, tags, p):\n",
    "    words_new, tags_new = [], []\n",
    "    for i in range(len(words)):\n",
    "        augword = words[i]\n",
    "\n",
    "        if (tags[i] == \"postal_code\"):\n",
    "            augword = pc_augment(augword, letter_aug= 0.9, num_aug= 0.8)\n",
    "        elif (tags[i] != \"unit\" and tags[i]!=\"pobox\" and tags[i]!=\"street_no\" and prob(p)):\n",
    "            augword = augment(augword)\n",
    "        elif (tags[i] != \"\" and tags[i]!=\"pobox\" and tags[i]!=\"street_no\" and prob(p)):\n",
    "\n",
    "        elif (tags[i] == \"unit\" or tags[i] ==\"pobox\" or tags[i]==\"street_no\" and prob(0.03)):\n",
    "            og = augword                \n",
    "            augword = num_augment(augword, letter_aug=0.95, num_aug=0.95)\n",
    "            # if tags[i] == \"street_no\" and og != augword:\n",
    "            #     print(og, augword, sep=\"   \")\n",
    "        if (tags[i] != \"unit\" and tags[i]!=\"pobox\" and tags[i]!=\"street_no\" and prob(0.02)):\n",
    "            augword = aug_split.augment(augword)[0]\n",
    "        \n",
    "        tags_new.extend([tags[i]] * len(augword.split()))\n",
    "        words_new.extend(augword.split())\n",
    "            \n",
    "    return words_new, tags_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(wt, tt, is_en = True):\n",
    "    # perform rearrangments\n",
    "    r = rand.uniform(0,1)\n",
    "    if r < 0.1:\n",
    "        str_wt, str_tt = [], []\n",
    "        nstr_wt, nstr_tt = [], []\n",
    "        for i in range(len(wt)):\n",
    "            if tt[i][:3] == \"str\" or tt[i] == \"unit\" or tt[i] == \"pobox\":\n",
    "                str_wt.append(wt[i])\n",
    "                str_tt.append(tt[i])\n",
    "            else:\n",
    "                nstr_wt.append(wt[i])\n",
    "                nstr_tt.append(tt[i])\n",
    "        msk = list(range(len(nstr_wt)))\n",
    "        rand.shuffle(msk)\n",
    "        wt = [nstr_wt[i] for i in msk]\n",
    "        tt = [nstr_tt[i] for i in msk]\n",
    "        iind = get_insertion_index(wt,tt)\n",
    "        wt,tt = wt[:iind] + str_wt + wt[iind:], tt[:iind] + str_tt + tt[iind:]\n",
    "    elif r < 0.65:\n",
    "        swappable_inds = [i for i in range(len(wt)) if not (tt[i][:3] == \"str\" or tt[i] == \"unit\" or tt[i] == \"pobox\")]\n",
    "        if len(swappable_inds) > 2:\n",
    "            i, j = rand.sample(swappable_inds, 2)\n",
    "            wt[i], wt[j] = wt[j], wt[i]\n",
    "            tt[i], tt[j] = tt[j], tt[i]\n",
    "    elif r < 0.8 and \"postal_code\" in tt:\n",
    "        i = tt.index(\"postal_code\")\n",
    "        swappable_inds = [i for i in range(len(wt)) if tt[i][:3] != \"str\"]\n",
    "        if len(swappable_inds) > 1:\n",
    "            j = rand.choice(swappable_inds)\n",
    "            wt[i], wt[j] = wt[j], wt[i]\n",
    "            tt[i], tt[j] = tt[j], tt[i]\n",
    "\n",
    "    std_words, nstd_words = [], []\n",
    "    pot_dup_words, pot_dup_tags = [], []\n",
    "    nstsno = None\n",
    "    \n",
    "    keep_street = prob(0.99)\n",
    "\n",
    "    for i in range(len(wt)):\n",
    "        assert isinstance(wt[i], str) == True\n",
    "        if tt[i] == \"city\":\n",
    "            std_words.append(wt[i])\n",
    "            nstd_words.append(wt[i])\n",
    "            if prob(0.8):\n",
    "                pot_dup_words.append(wt[i])\n",
    "                pot_dup_tags.append(tt[i])\n",
    "        elif tt[i] == \"postal_code\":\n",
    "            pc = wt[i].replace(\" \", \"\")\n",
    "            if len(pc) < 6 or prob(0.2):\n",
    "                continue\n",
    "            else:\n",
    "                if wt[i][3] != \" \" and len(wt[i])==6:\n",
    "                    wt[i] = wt[i][:3] + \" \" + wt[i][3:]\n",
    "                    print(wt[i])\n",
    "                if prob(0.02):\n",
    "                    wt[i] = pc[:3]\n",
    "                elif prob(0.02):\n",
    "                    wt[i] = pc[3:]\n",
    "                std_words.append(wt[i])\n",
    "                nstd_words.append(wt[i])\n",
    "                temp_snapshot = deepcopy(std_words), deepcopy(nstd_words)\n",
    "\n",
    "                if prob(0.8):\n",
    "                    pot_dup_words.append(wt[i])\n",
    "                    pot_dup_tags.append(tt[i])\n",
    "        elif tt[i] == \"province\":\n",
    "            nst = wt[i] if wt[i] not in to_non_stand_prov or prob(0.6) else rand.choice(to_non_stand_prov[wt[i]])\n",
    "            std_words.append(wt[i])\n",
    "            nstd_words.append(nst)\n",
    "            if prob(0.6):\n",
    "                pot_dup_words.append(nst)\n",
    "                pot_dup_tags.append(tt[i])\n",
    "        elif tt[i] == \"country\":\n",
    "            assert wt[i] == \"ca\", f\"{wt[i]} {wt} {tt}\"\n",
    "            nst = wt[i] if prob(0.7) else \"canada\"\n",
    "            std_words.append(wt[i])\n",
    "            nstd_words.append(nst)\n",
    "            if prob(0.5):\n",
    "                pot_dup_words.append(nst)\n",
    "                pot_dup_tags.append(tt[i])\n",
    "        elif tt[i] == \"rr\":\n",
    "            std_words.append(wt[i])\n",
    "            nst = wt[i].replace(\"rr\", rand.choice(to_non_stand_num_term[\"rr\"])) if prob(0.3) else wt[i]\n",
    "            nstd_words.append(nst)\n",
    "        elif tt[i] == \"pobox\":\n",
    "                std_words.append(f\"po box {wt[i]}\")\n",
    "                unit_sep = rand.choice([\"#\", \"# \", \" #\", \" # \", \"\", \" \", \" \", \" \"])\n",
    "                nstd_words.append(rand.choice([f\"po box{unit_sep}{wt[i]} \", f\"{rand.choice(to_non_stand_num_term[\"po box\"])}{unit_sep}{wt[i]}\"]))\n",
    "        \n",
    "        if keep_street:\n",
    "            if tt[i] == \"unit\":\n",
    "                std_words.append(f\"unit {wt[i]}\")\n",
    "                if \"street_no\" in tt and prob(0.2):\n",
    "                    ind = tt.index(\"street_no\")\n",
    "                    nstsno = f\"{wt[i]}-{wt[ind]}\"\n",
    "                else:\n",
    "                    unit_sep = rand.choice([\"#\", \"# \", \" #\", \" # \", \"\", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \"])\n",
    "                    nstd_words.append(choice([f\"unit{unit_sep}{wt[i]}\", f\"{unit_sep}{wt[i]}\".strip(), f\"{rand.choice(to_non_stand_num_term[\"unit\"])}{unit_sep}{wt[i]}\"], p=[0.2, 0.5, 0.3]))\n",
    "            elif tt[i] == \"ph\":\n",
    "                std_words.append(f\"ph {wt[i]}\")\n",
    "                unit_sep = rand.choice([\"#\", \"# \", \" #\", \" # \", \"\", \" \", \" \", \" \"])\n",
    "                nstd_words.append(rand.choice([f\"ph {unit_sep}{wt[i]} \", f\"{rand.choice(to_non_stand_num_term[\"ph\"])}{unit_sep}{wt[i]}\"]))\n",
    "            elif tt[i] == \"street_no\":\n",
    "                std_words.append(wt[i])\n",
    "                nstd_words.append(wt[i] if nstsno == None else nstsno)\n",
    "                if prob(0.3):\n",
    "                    pot_dup_words.append(wt[i])\n",
    "                    pot_dup_tags.append(tt[i])\n",
    "            elif tt[i] == \"str_name\":\n",
    "                sst = \" \".join([w if w not in to_std else to_std[w] for w in wt[i].split()])\n",
    "                nst = \" \".join([w if w not in to_non_std or prob(0.7) else rand.choice(to_non_std[w]) for w in sst.split()])\n",
    "                std_words.append(sst)\n",
    "                nstd_words.append(nst)\n",
    "                pot_dup_words.append(nst)\n",
    "                pot_dup_tags.append(tt[i])\n",
    "            elif tt[i] == \"str_type\"and prob(0.95):\n",
    "                sst = \"\"\n",
    "                if wt[i] in to_stand_street_type:\n",
    "                    sst = to_stand_street_type[wt[i]]\n",
    "                else:\n",
    "                    sst = \" \".join([w if w not in to_stand_street_type else to_stand_street_type[w] for w in wt[i].split()])\n",
    "\n",
    "                nst = \" \".join([w if w not in to_non_stand_street_type or prob(0.3) else rand.choice(to_non_stand_street_type[w]) for w in sst.split()])\n",
    "                std_words.append(sst)\n",
    "                nstd_words.append(nst)\n",
    "                pot_dup_words.append(nst)\n",
    "                pot_dup_tags.append(tt[i])\n",
    "            elif tt[i] == \"str_dir\" and prob(0.95):\n",
    "                sst = wt[i] if wt[i] not in to_stand_street_dir else to_stand_street_dir[wt[i]]\n",
    "                nst = sst if sst not in to_non_stand_street_dir or prob(0.3) else rand.choice(to_non_stand_street_dir[sst])\n",
    "                std_words.append(sst)\n",
    "                nstd_words.append(nst)\n",
    "                if prob(0.9):\n",
    "                    pot_dup_words.append(nst)\n",
    "                    pot_dup_tags.append(tt[i])\n",
    "\n",
    "        # else:\n",
    "        #     std_words.append(wt[i])\n",
    "        #     nstd_words.append(wt[i])\n",
    "\n",
    "    # if prob(0.03):\n",
    "    #     nstd_words.extend(pot_dup_words)\n",
    "    #     tt.extend(pot_dup_tags)\n",
    "    \n",
    "\n",
    "    # final augmentation, non standard only \n",
    "                    \n",
    "    tags = tt\n",
    "    if nstsno != None:\n",
    "        tt.remove(\"unit\")\n",
    "    if prob(0.75): \n",
    "        nstd_words, tags = aug_words_tags(nstd_words, tt, 0.3)\n",
    "\n",
    "    nstd_res = \" \".join(nstd_words)\n",
    "\n",
    "    # if prob(0.03):\n",
    "    #     iind = get_insertion_index(nstd_words,tags)\n",
    "    #     nstd_words,tags = wt[:iind] + [rand_gibberish_address()] + wt[iind:], tt[:iind] + [\"gibberish\"] + tt[iind:]\n",
    "    #     nstd_res = \" \".join(nstd_words)\n",
    "    # elif prob(0.5):\n",
    "\n",
    "    if prob(0.4):\n",
    "        nstd_res = rm_space_augment(nstd_res, keep_ws_p=0.8)\n",
    "\n",
    "    if prob(0.02) and is_en:\n",
    "        sep = [\" \", \"\"]\n",
    "        if prob(0.7):\n",
    "            nstd_res = nstd_res + choice(sep, p=[0.9, 0.1]) + rm_space_augment(augment(rand.choice(insurace_suffix), letter_aug=0.8))\n",
    "        if prob(0.7):\n",
    "            nstd_res = rm_space_augment(augment(rand.choice(insurace_prefix), letter_aug=0.8)) + choice(sep, p=[0.9, 0.1]) + nstd_res  \n",
    "\n",
    "    if prob(0.01) and not is_en:\n",
    "        sep = [\" \", \"\"]\n",
    "        if prob(0.7):\n",
    "            nstd_res = nstd_res + choice(sep, p=[0.9, 0.1]) + rm_space_augment(augment(rand.choice(insurace_suffix_fr), letter_aug=0.8))\n",
    "        if prob(0.7):\n",
    "            nstd_res = rm_space_augment(augment(rand.choice(insurace_prefix_fr), letter_aug=0.8)) + choice(sep, p=[0.9, 0.1]) + nstd_res  \n",
    "\n",
    "    std_res = \" \".join(std_words)\n",
    "    return std_res, nstd_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    a,b = convert([\"egmont\", \"8096\", \"watkins\",\"landing\", \"nw\", \"v0n 1n0\", \"ca\" ,\"bc\"], [\"city\", \"street_no\", \"str_name\", \"str_type\", \"str_dir\", \"postal_code\", \"country\", \"province\"])\n",
    "    if \"v0n\" not in a and \"v0n\" in \"b\":\n",
    "        print(a,b)\n",
    "    if \"von\" not in a and \"v0n\" in \"b\":\n",
    "        print(a,b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\O'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\O'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_33672\\3244565301.py:5: SyntaxWarning: invalid escape sequence '\\O'\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_33672\\3244565301.py:17: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  cpcdf = pd.read_csv(\"data\\CanadianPostalCodes202312.csv\")\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_33672\\3244565301.py:26: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  city_df = pd.read_csv(\"data\\cgn_canada_csv_eng.csv\")\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_33672\\3244565301.py:5: DtypeWarning: Columns (2,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_33672\\3244565301.py:5: DtypeWarning: Columns (2,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_33672\\3244565301.py:5: DtypeWarning: Columns (2,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_33672\\3244565301.py:5: DtypeWarning: Columns (9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_33672\\3244565301.py:5: DtypeWarning: Columns (2,8,9,10,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_33672\\3244565301.py:5: DtypeWarning: Columns (7,8,9,10,15,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_33672\\3244565301.py:5: DtypeWarning: Columns (9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_33672\\3244565301.py:26: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  city_df = pd.read_csv(\"data\\cgn_canada_csv_eng.csv\")\n"
     ]
    }
   ],
   "source": [
    "statcan_data = []\n",
    "statcan_relevant_cols = [\"street_no\", \"street\", \"city\", \"postal_code\", \"Province\"]\n",
    "dtypes = {key: str for key in statcan_relevant_cols}\n",
    "for prov in province_lst: \n",
    "    df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
    "    df[\"province\"] = prov\n",
    "    df = df[(df[\"street\"] != \"UNASSIGNED\")& (df[\"postal_code\"] != \"UNASSIGNED\")& (df[\"street_no\"].str.contains(\"-\") == False)]\n",
    "    df = df.dropna(subset  = [\"str_name\"])\n",
    "    # df = df.drop(df[df[\"postal_code\"].isnull()].sample(frac=0.5).index)\n",
    "    statcan_data.append(df)\n",
    "\n",
    "statcan_df = pd.concat(statcan_data, ignore_index=True)\n",
    "statcan_df[\"non-std-address\"] = \"\"\n",
    "statcan_df[\"std-address\"] = \"\"\n",
    "statcan_df.head()\n",
    "\n",
    "cpcdf = pd.read_csv(\"data\\CanadianPostalCodes202312.csv\")\n",
    "cpcdf = cpcdf[[\"POSTAL_CODE\", \"CITY\", \"PROVINCE_ABBR\"]]\n",
    "cpcdf.rename(columns={\"POSTAL_CODE\": \"postal_code\", \"CITY\": \"city\", \"PROVINCE_ABBR\": \"province\"}, inplace=True)\n",
    "cpcdf[\"street_no\"] = \"\"\n",
    "cpcdf[\"str_name\"] = \"\"\n",
    "cpcdf[\"str_type\"] = \"\"\n",
    "cpcdf[\"non-std-address\"] = \"\"\n",
    "cpcdf[\"std-address\"] = \"\"\n",
    "\n",
    "city_df = pd.read_csv(\"data\\cgn_canada_csv_eng.csv\")\n",
    "city_df = city_df[(city_df['Generic Category']== \"Populated Place\") & (city_df['Language']== \"Undetermined\")].drop_duplicates(subset=['Geographical Name'])\n",
    "city_df['std-address'] = city_df['Geographical Name'].apply(lambda city : city.lower())\n",
    "city_df['non-std-address']=city_df['std-address'].apply(lambda city : augment(city.lower(), letter_aug=0.5) if prob(0.9) else aug_split.augment(augment(city.lower(), letter_aug=0.5))[0])\n",
    "city_df = city_df[['non-std-address', 'std-address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5582851"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(statcan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in statcan_df.iterrows():\n",
    "    wt, tt = [], []\n",
    "    illegal_pc = [\"VACANT\", \"QUEENS\", \"RMC\", \"na\", \"UNKNOWN\", \"UNASSIGNED\"]\n",
    "    \n",
    "    if prob(0.3):\n",
    "        wt.append(rand_unit_num())\n",
    "        tt.append(\"unit\")\n",
    "    elif prob(0.2):\n",
    "        wt.append(choice([f\"{rand.randint(1,9999)}\", f\"{rand.randint(1,99999)}\"], p= [0.8, 0.2]))\n",
    "        tt.append(\"pobox\")\n",
    "    elif prob(0.02):\n",
    "        wt.append(rand_unit_num())\n",
    "        tt.append(\"ph\")\n",
    "\n",
    "    row[\"rr\"] = rand_rr() if prob(0.001) else \"\"\n",
    "    row[\"postal_code\"] = row[\"postal_code\"] if row[\"postal_code\"] not in illegal_pc else \"\"\n",
    "\n",
    "    for tag in [\"street_no\", \"str_name\", \"str_type\", \"str_dir\", \"rr\", \"city\", \"postal_code\", \"province\"]:\n",
    "        if isinstance(row[tag], str) and not row[tag].isspace() and not row[tag] == \"\":\n",
    "            tt.append(tag)\n",
    "            wt.append(row[tag].lower())\n",
    "\n",
    "    if prob(0.1):\n",
    "        wt.append(\"ca\")\n",
    "        tt.append(\"country\")\n",
    "\n",
    "    std_adr, nstd_adr = convert(wt, tt, is_en=row[\"province\"].lower() != \"qc\")\n",
    "    statcan_df.at[i, \"non-std-address\"] = nstd_adr\n",
    "    statcan_df.at[i, \"std-address\"] = std_adr\n",
    "\n",
    "statcan_df = statcan_df[cols]\n",
    "statcan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pc_std = []\n",
    "single_pc_nstd = []\n",
    "\n",
    "for i, row in cpcdf.iterrows():\n",
    "    pc = row[\"postal_code\"].replace(\"-\", \" \").lower()\n",
    "    if prob(0.01) and len(pc) == 7:\n",
    "        single_pc_std.append(pc)\n",
    "        pc = pc_augment(pc, num_aug= 0.5).split()\n",
    "        pc_word = choice([f\"{pc[0]}{pc[1]}\", f\"{pc[0]} {pc[1]}\", f\"{pc[1]}{pc[0]}\"], p=[0.3, 0.68, 0.02])\n",
    "        if (len(pc_word.split())) == 2 and prob(0.1):\n",
    "            pc_word = aug_split.augment(pc_word)[0]\n",
    "        single_pc_nstd.append(pc_word.lower())\n",
    "\n",
    "    wt, tt = [], []\n",
    "    \n",
    "    if row[\"province\"].lower() != \"qc\":\n",
    "        row[\"str_name\"], row[\"str_type\"] = fake_en.street_name().lower().split() if prob(0.995) else (rand_ordinal_street(), rand.choice(street_type))\n",
    "    if row[\"province\"].lower() == \"qc\":\n",
    "        row[\"str_name\"], row[\"str_type\"] = fake_fr.street_name().lower().split() if prob(0.995) else (rand_ordinal_street(), rand.choice(street_type))\n",
    "    \n",
    "    row[\"street_no\"] = f\"{rand.randint(1,9999)}\" if prob(0.95) else \"\"\n",
    "    row[\"str_dir\"] = rand.choice(street_dir) if prob(0.1) else \"\"\n",
    "    row[\"rr\"] = rand_rr() if prob(0.001) else \"\"\n",
    "\n",
    "    if prob(0.2):\n",
    "        wt.append(rand_unit_num())\n",
    "        tt.append(\"unit\")\n",
    "    elif prob(0.2):\n",
    "        wt.append(choice([f\"{rand.randint(1,9999)}\", f\"{rand.randint(1,99999)}\"], p= [0.8, 0.2]))\n",
    "        tt.append(\"pobox\")\n",
    "    elif prob(0.02):\n",
    "        wt.append(rand_unit_num())\n",
    "        tt.append(\"ph\")\n",
    "    \n",
    "    rel_tags = [\"street_no\", \"str_name\", \"str_type\", \"str_dir\", \"rr\", \"city\", \"postal_code\", \"province\"]\n",
    "    if row[\"province\"].lower() == \"qc\" and prob(0.3):\n",
    "        rel_tags = [\"street_no\", \"str_type\", \"str_name\", \"rr\", \"city\", \"postal_code\", \"province\"]\n",
    "    for tag in rel_tags:\n",
    "        if isinstance(row[tag], str) and not row[tag].isspace() and not row[tag] == \"\":\n",
    "            tt.append(tag)\n",
    "            wt.append(row[tag].lower())\n",
    "\n",
    "    if prob(0.1):\n",
    "        wt.append(\"ca\")\n",
    "        tt.append(\"country\")\n",
    "\n",
    "    std_adr, nstd_adr = convert(wt, tt, is_en=row[\"province\"].lower() != \"qc\")\n",
    "    cpcdf.at[i, \"non-std-address\"] = nstd_adr\n",
    "    cpcdf.at[i, \"std-address\"] = std_adr\n",
    "\n",
    "cpcdf = cpcdf[cols]\n",
    "pc_df = pd.DataFrame({\"non-std-address\": single_pc_nstd, \"std-address\": single_pc_std})\n",
    "cpcdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "pc_city_map = {\n",
    "    \"P0B 1A0\": \"Baysville\",\n",
    "    \"P0B 1E0\": \"Milford Bay\",\n",
    "    \"P0B 1G0\": \"Minett\",\n",
    "    \"P0B 1J0\": \"Port Carling\",\n",
    "    \"P0B 1K0\": \"Port Sandfield\",\n",
    "    \"P0B 1L0\": \"Port Sydney\",\n",
    "    \"P0B 1M0\": \"Utterson\",\n",
    "    \"P0B 1P0\": \"Windermere\",\n",
    "    \"P0H 1A0\": \"Arnstein\",\n",
    "    \"P0H 1B0\": \"Astorville\",\n",
    "    \"P0H 1C0\": \"Bear Island\",\n",
    "    \"P0H 1E0\": \"Bonfield\",\n",
    "    \"P0H 1G0\": \"Cache Bay\",\n",
    "    \"P0H 1H0\": \"Callander\",\n",
    "    \"P0H 1J0\": \"Commanda\",\n",
    "    \"P0H 1K0\": \"Corbeil\",\n",
    "    \"P0H 1L0\": \"Crystal Falls\",\n",
    "    \"P0H 1M0\": \"Field\",\n",
    "    \"P0H 1N0\": \"Golden Valley\",\n",
    "    \"P0H 1P0\": \"Hornell Heights\",\n",
    "    \"P0H 1R0\": \"Lavigne\",\n",
    "    \"P0H 1S0\": \"Loring\",\n",
    "    \"P0H 1T0\": \"Marten River\",\n",
    "    \"P0H 1V0\": \"Mattawa\",\n",
    "    \"P0H 1W0\": \"Nipissing\",\n",
    "    \"P0H 1Y0\": \"Port Loring\",\n",
    "    \"P0H 1Z0\": \"Powassan\",\n",
    "    \"P0H 2A0\": \"Redbridge\",\n",
    "    \"P0H 2C0\": \"River Valley\",\n",
    "    \"P0H 2E0\": \"Rutherglen\",\n",
    "    \"P0H 2H0\": \"Temagami\",\n",
    "    \"P0H 2J0\": \"Thorne\",\n",
    "    \"P0H 2K0\": \"Tilden Lake\",\n",
    "    \"P0H 2L0\": \"Trout Creek\",\n",
    "    \"P0H 2M0\": \"Verner\",\n",
    "    \"P0H 2N0\": \"Warren\",\n",
    "    \"P0H 2R0\": \"Restoule\",\n",
    "    \"V0N 1A0\":\" Alert Bay\",\n",
    "    \"V0N 1B0\":\" Whistler\",\n",
    "    \"V0N 1E0\":\" Blubber Bay\",\n",
    "    \"V0N 1G0\":\" Bowen Island\",\n",
    "    \"V0N 1H0\":\" Brackendale\",\n",
    "    \"V0N 1J0\":\" Britannia Beach\",\n",
    "    \"V0N 1K0\":\" Coal Harbour\",\n",
    "    \"V0N 1L0\":\" D'Arcy\",\n",
    "    \"V0N 1M0\":\" Dawsons Landing\",\n",
    "    \"V0N 1N0\":\" Egmont\",\n",
    "    \"V0N 1P0\":\" Galiano Island\",\n",
    "    \"V0N 1S0\":\" Garden Bay\",\n",
    "    \"V0N 1T0\":\" Garibaldi Highlands\",\n",
    "    \"V0N 1V0\":\" Gibsons\",\n",
    "    \"V0N 1W0\":\" Gillies Bay\",\n",
    "    \"V0N 1Z0\":\" Holberg\",\n",
    "    \"V0N 2B0\":\" Kingcome Inlet\",\n",
    "    \"V0N 2E0\":\" Lions Bay\",\n",
    "    \"V0N 2G0\":\" Lund\",\n",
    "    \"V0N 2H0\":\" Madeira Park\",\n",
    "    \"V0N 2H1\":\" Pender Harbour\",\n",
    "    \"V0N 2J0\":\" Mayne Island\",\n",
    "    \"V0N 2K0\":\" Mount Currie\",\n",
    "    \"V0N 2L0\":\" Pemberton\",\n",
    "    \"V0N 2M0\":\" Pender Island\",\n",
    "    \"V0N 2N0\":\" Port Alice\",\n",
    "    \"V0N 2P0\":\" Port Hardy\",\n",
    "    \"V0N 2R0\":\" Port McNeill\",\n",
    "    \"V0N 2S0\":\" Port Mellon\",\n",
    "    \"V0N 2V0\":\" Quatsino\",\n",
    "    \"V0N 2W0\":\" Roberts Creek\",\n",
    "    \"V0N 2Y0\":\" Saturna\",\n",
    "    \"V0N 3A0\":\" Sechelt\",\n",
    "    \"V0N 3B0\":\" Seton Portage\",\n",
    "    \"V0N 3C0\":\" Shalalth\",\n",
    "    \"V0N 3E0\":\" Sointula\",\n",
    "    \"V0N 3J0\":\" Telegraph Cove\",\n",
    "    \"V0N 3K0\":\" Van Anda\",\n",
    "    \"V0N 3L0\":\" Winter Harbour\",\n",
    "    \"V0N 3P0\":\" Woss\",\n",
    "    \"V0N 3V0\":\" Gibsons\",\n",
    "    \"V0N 3Z0\":\" Furry Creek\",\n",
    "    \"V0R 1A0\":\" Ahousat\",\n",
    "    \"V0R 1B0\":\" Bamfield\",\n",
    "    \"V0R 1G0\":\" Bowser\",\n",
    "    \"V0R 1H0\":\" Cassidy\",\n",
    "    \"V0R 1K0\":\" Chemainus\",\n",
    "    \"V0R 1L0\":\" Cobble Hill\",\n",
    "    \"V0R 1M0\":\" Coombs\",\n",
    "    \"V0R 1N0\":\" Cowichan Bay\",\n",
    "    \"V0R 1R0\":\" Crofton\",\n",
    "    \"V0R 1S0\":\" Cumberland\",\n",
    "    \"V0R 1T0\":\" Denman Island\",\n",
    "    \"V0R 1V0\":\" Errington\",\n",
    "    \"V0R 1W0\":\" Fanny Bay\",\n",
    "    \"V0R 1X0\":\" Gabriola\",\n",
    "    \"V0R 1Y0\":\" Honeymoon Bay\",\n",
    "    \"V0R 1Z0\":\" Hornby Island\",\n",
    "    \"V0R 2B0\":\" Kildonan\",\n",
    "    \"V0R 2C0\":\" Koksilah\",\n",
    "    \"V0R 2G0\":\" Lake Cowichan\",\n",
    "    \"V0R 2H0\":\" Lantzville\",\n",
    "    \"V0R 2J0\":\" Lasqueti\",\n",
    "    \"V0R 2K0\":\" Lazo\",\n",
    "    \"V0R 2L0\":\" Malahat\",\n",
    "    \"V0R 2M0\":\" Merville\",\n",
    "    \"V0R 2N0\":\" Mesachie Lake\",\n",
    "    \"V0R 2P0\":\" Mill Bay\",\n",
    "    \"V0R 2V0\":\" Royston\",\n",
    "    \"V0R 2W0\":\" Shawnigan Lake\",\n",
    "    \"V0R 2Y0\":\" Thetis Island\",\n",
    "    \"V0R 2Z0\":\" Tofino\",\n",
    "    \"V0R 3A0\":\" Ucluelet\",\n",
    "    \"V0R 3B0\":\" Union Bay\",\n",
    "    \"V0R 3C0\":\" Westholme\",\n",
    "    \"V0R 3E1\":\" Youbou\",\n",
    "    \"V0R 4K0\":\" Chemainus\",\n",
    "    \"V0R 5K0\":\" Penelakut Island\",\n",
    "    \"L0N 1A0\":\" Alton\",\n",
    "\"L0N 1B0\":\" Belfountain\",\n",
    "\"L0N 1C0\":\" Caledon Village\",\n",
    "\"L0N 1E0\":\" Caledon East\",\n",
    "\"L0N 1G0\":\" Grand Valley\",\n",
    "\"L0N 1H0\":\" Honeywood\",\n",
    "\"L0N 1J0\":\" Horning's Mills\",\n",
    "\"L0N 1K0\":\" Inglewood\",\n",
    "\"L0N 1L0\":\" Laurel\",\n",
    "\"L0N 1M0\":\" Mansfield\",\n",
    "\"L0N 1N0\":\" Orton\",\n",
    "\"L0N 1P0\":\" Palgrave\",\n",
    "\"L0N 1R0\":\" Rosemont\",\n",
    "\"L0N 1S0\":\" Shelburne\",\n",
    "\"N0N 1A0\":\" Alvinston\",\n",
    "\"N0N 1B0\":\" Brigden\",\n",
    "\"N0N 1C0\":\" BrightΓÇÖs Grove\",\n",
    "\"N0N 1E0\":\" Camlachie\",\n",
    "\"N0N 1G0\":\" Corunna\",\n",
    "\"N0N 1H0\":\" Courtright\",\n",
    "\"N0N 1J0\":\" Forest\",\n",
    "\"N0N 1K0\":\" Inwood\",\n",
    "\"N0N 1M0\":\" Mooretown\",\n",
    "\"N0N 1N0\":\" Oil City\",\n",
    "\"N0N 1P0\":\" Oil Springs\",\n",
    "\"N0N 1R0\":\" Petrolia\",\n",
    "\"N0N 1T0\":\" Wyoming\",\n",
    "\"A0N 1A0\":\" Aguathuna\",\n",
    "\"A0N 1B0\":\" Barachois Brook\",\n",
    "\"A0N 1C0\":\" Cape Ray\",\n",
    "\"A0N 1E0\":\" Cape St. George\",\n",
    "\"A0N 1G0\":\" Cartyville\",\n",
    "\"A0N 1H0\":\" Codroy\",\n",
    "\"A0N 1J0\":\" Doyles\",\n",
    "\"A0N 1K0\":\" Grand Bay East\",\n",
    "\"A0N 1M0\":\" Heatherton\",\n",
    "\"A0N 1N0\":\" Highlands\",\n",
    "\"A0N 1P0\":\" Jeffrey's\",\n",
    "\"A0N 1R0\":\" Lourdes\",\n",
    "\"A0N 1S0\":\" Noels Pond\",\n",
    "\"A0N 1T0\":\" Port au Port\",\n",
    "\"A0N 1V0\":\" Robinsons\",\n",
    "\"A0N 1W0\":\" St. Andrew's\",\n",
    "\"A0N 1X0\":\" St. David's\",\n",
    "\"A0N 1Y0\":\" St. Fintan's\",\n",
    "\"A0N 1Z0\":\" St. George's\",\n",
    "\"A0N 2B0\":\" South Branch\",\n",
    "\"A0N 2C0\":\" Stephenville Crossing\",\n",
    "\"A0N 2E0\":\" West Bay Centre\",\n",
    "\"A0N 2G0\":\" Black Duck Siding\",\n",
    "\"A0N 2H0\":\" Burgeo\",\n",
    "\"A0N 2J0\":\" Ramea\",\n",
    "\"A0N 2K0\":\" Fran├ºois\",\n",
    "\"A0N 2L0\":\" Grey River\",\n",
    "\"B0N 1C0\":\" Brookfield\",\n",
    "\"B0N 1E0\":\" Centre Burlington\",\n",
    "\"B0N 1G0\":\" Cheverie\",\n",
    "\"B0N 1H0\":\" Curry's Corner\",\n",
    "\"B0N 1J0\":\" Densmore Mills\",\n",
    "\"B0N 1K0\":\" Elderbank\",\n",
    "\"B0N 1L0\":\" Ellershouse\",\n",
    "\"B0N 1P0\":\" Kennetcook\",\n",
    "\"B0N 1T0\":\" Maitland\",\n",
    "\"B0N 1V0\":\" Meaghers Grant\",\n",
    "\"B0N 1W0\":\" Micmac\",\n",
    "\"B0N 1X0\":\" Middle Musquodoboit\",\n",
    "\"B0N 1Y0\":\" Milford Station, Milford\",\n",
    "\"B0N 1Z0\":\" Mount Uniacke\",\n",
    "\"B0N 2A0\":\" Newport\",\n",
    "\"B0N 2B0\":\" Newport Station\",\n",
    "\"B0N 2C0\":\" Noel\",\n",
    "\"B0N 2E0\":\" Ste-Croix\",\n",
    "\"B0N 2G0\":\" Scotch Village\",\n",
    "\"B0N 2H0\":\" Shubenacadie\",\n",
    "\"B0N 2J0\":\" Stewiacke\",\n",
    "\"B0N 2K0\":\" Summerville\",\n",
    "\"B0N 2L0\":\" Upper Kennetcook\",\n",
    "\"B0N 2M0\":\" Upper Musquodoboit\",\n",
    "\"B0N 2N0\":\" Upper Rawdon\",\n",
    "\"B0N 2P0\":\" Upper Stewiacke\",\n",
    "\"B0N 2R0\":\" Walton\",\n",
    "\"B0N 2T0\":\" Windsor\",\n",
    "\"B0N 3A0\":\" Ellershouse\",\n",
    "\"G0N 1B0\":\" Saint-Joseph-de-Coleraine, Saint-Julien\",\n",
    "\"G0N 1C0\":\" Sainte-Clotilde-de-Beauce\",\n",
    "\"G0N 1E0\":\" Disraeli\",\n",
    "\"G0N 1E1\":\" Sainte-Prax├¿de\",\n",
    "\"G0N 1E2\":\" Saint-Jacques-le-Majeur-de-Wolfestown\",\n",
    "\"G0N 1G0\":\" Sacr├⌐-C┼ôur-de-J├⌐sus\",\n",
    "\"G0N 1H0\":\" East Broughton\",\n",
    "\"G0N 1J0\":\" Saint-Jacques-de-Leeds\",\n",
    "\"G0N 1K0\":\" Kinnear's Mills\",\n",
    "\"G0N 1M0\":\" Saint-Adrien-d'Irlande\",\n",
    "\"G0N 1N0\":\" Saint-Ferdinand\",\n",
    "\"G0N 1P0\":\" Saint-Fr├⌐d├⌐ric\",\n",
    "\"G0N 1R0\":\" Saint-Jules\",\n",
    "\"G0N 1S0\":\" Adstock\",\n",
    "\"G0N 1T0\":\" Saint-Pierre-de-Broughton\",\n",
    "\"G0N 1V0\":\" Saint-S├⌐verin\",\n",
    "\"G0N 1X0\":\" Tring-Jonction\",\n",
    "\"S0N 0A0\":\" Abbey\",\n",
    "\"S0N 0B0\":\" Admiral\",\n",
    "\"S0N 0C0\":\" Aneroid\",\n",
    "\"S0N 0E0\":\" Blumenhof\",\n",
    "\"S0N 0G0\":\" Bracken\",\n",
    "\"S0N 0H0\":\" Burstall\",\n",
    "\"S0N 0J0\":\" Cabri\",\n",
    "\"S0N 0K0\":\" Cadillac\",\n",
    "\"S0N 0M0\":\" Claydon\",\n",
    "\"S0N 0N0\":\" Climax\",\n",
    "\"S0N 0P0\":\" Consul\",\n",
    "\"S0N 0S0\":\" Dollard\",\n",
    "\"S0N 0T0\":\" Eastend\",\n",
    "\"S0N 0V0\":\" Fox Valley\",\n",
    "\"S0N 0W0\":\" Frontier\",\n",
    "\"S0N 0X0\":\" Glenbain\",\n",
    "\"S0N 0Y0\":\" Golden Prairie\",\n",
    "\"S0N 1A0\":\" Gull Lake\",\n",
    "\"S0N 1C0\":\" Hazenmore\",\n",
    "\"S0N 1E0\":\" Hazlet\",\n",
    "\"S0N 1G0\":\" Lancer\",\n",
    "\"S0N 1H0\":\" Leader\",\n",
    "\"S0N 1L0\":\" Liebenthal\",\n",
    "\"S0N 1M0\":\" McMahon\",\n",
    "\"S0N 1N0\":\" Maple Creek\",\n",
    "\"S0N 1P0\":\" Mendham\",\n",
    "\"S0N 1S0\":\" Neidpath\",\n",
    "\"S0N 1T0\":\" Neville\",\n",
    "\"S0N 1V0\":\" Orkney\",\n",
    "\"S0N 1W0\":\" Pambrun\",\n",
    "\"S0N 1X0\":\" Pennant Station\",\n",
    "\"S0N 1Y0\":\" Piapot\",\n",
    "\"S0N 1Z0\":\" Ponteix\",\n",
    "\"S0N 2A0\":\" Portreeve\",\n",
    "\"S0N 2B0\":\" Prelate\",\n",
    "\"S0N 2E0\":\" Richmound\",\n",
    "\"S0N 2G0\":\" Robsart\",\n",
    "\"S0N 2H0\":\" Sceptre\",\n",
    "\"S0N 2L0\":\" Shackleton\",\n",
    "\"S0N 2M0\":\" Shaunavon\",\n",
    "\"S0N 2N0\":\" Simmie\",\n",
    "\"S0N 2P0\":\" Stewart Valley\",\n",
    "\"S0N 2R0\":\" Success\",\n",
    "\"S0N 2S0\":\" Tompkins\",\n",
    "\"S0N 2T0\":\" Val Marie\",\n",
    "\"S0N 2V0\":\" Vanguard\",\n",
    "\"S0N 2W0\":\" Vidora\",\n",
    "\"S0N 2X0\":\" Webb\",\n",
    "\"S0N 2Y0\":\" Wymark\",\n",
    "}\n",
    "\n",
    "pc_to_prov = {\n",
    "    \"a\" : \"nl\",\n",
    "    \"b\" : \"ns\",\n",
    "    \"g\" : \"qc\",\n",
    "    \"h\" : \"qc\",\n",
    "    \"j\" : \"qc\",\n",
    "    \"k\" : \"on\",\n",
    "    \"l\" : \"on\",\n",
    "    \"m\" : \"on\",\n",
    "    \"n\" : \"on\",\n",
    "    \"p\" : \"on\",\n",
    "    \"r\" : \"mb\",\n",
    "    \"s\" : \"sk\",\n",
    "    \"t\" : \"ab\",\n",
    "    \"v\" : \"bc\"\n",
    "}\n",
    "\n",
    "std = []\n",
    "nstd = []\n",
    "\n",
    "for k in pc_city_map.keys():\n",
    "    pc = k.lower()\n",
    "    for i in range(1000):\n",
    "        city =  pc_city_map[k].lower()\n",
    "\n",
    "        wt,tt = [], []\n",
    "        \n",
    "        if prob(0.1):\n",
    "            wt.append(rand_unit_num())\n",
    "            tt.append(\"unit\")\n",
    "        elif prob(0.5):\n",
    "            wt.append(f\"{rand.randint(1,9999)}\")\n",
    "            tt.append(\"pobox\")\n",
    "\n",
    "        wt.append(f\"{rand.randint(1,9999)}\")\n",
    "        tt.append(\"street_no\")\n",
    "\n",
    "        if prob(0.995):\n",
    "            sn, st = fake_en.street_name().lower().split()\n",
    "            wt.append(sn)\n",
    "            tt.append(\"str_name\")\n",
    "            wt.append(st)\n",
    "            tt.append(\"str_type\")\n",
    "        else:\n",
    "            wt.append(rand_ordinal_street())\n",
    "            tt.append(\"str_name\")\n",
    "            wt.append(rand.choice(street_type))\n",
    "            tt.append(\"str_type\")\n",
    "\n",
    "        if prob(0.1):\n",
    "            wt.append(rand.choice(street_dir))\n",
    "            tt.append(\"str_dir\")\n",
    "\n",
    "        wt.append(city)\n",
    "        tt.append(\"city\")\n",
    "\n",
    "        wt.append(pc)\n",
    "        tt.append(\"postal_code\")\n",
    "\n",
    "        wt.append(pc_to_prov[pc[0]])\n",
    "        tt.append(\"province\")\n",
    "        \n",
    "        if prob(0.4):\n",
    "            wt.append(\"ca\")\n",
    "            tt.append(\"country\")\n",
    "        \n",
    "        tmp_wt = copy.deepcopy(wt)\n",
    "        tmp_tt = copy.deepcopy(tt)\n",
    "        std_adr, nstd_adr = convert(wt, tt, is_en=pc_to_prov[pc[0]] != \"qc\")\n",
    "                                \n",
    "        std.append(std_adr)\n",
    "        nstd.append(nstd_adr)\n",
    "\n",
    "popc_df = pd.DataFrame({\"non-std-address\": nstd, \"std-address\": std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statcan_df=statcan_df.reindex(columns=[\"non-std-address\", \"std-address\"])\n",
    "cpcdf=cpcdf.reindex(columns=[\"non-std-address\", \"std-address\"])\n",
    "all_df = pd.concat([statcan_df, cpcdf, pc_df, popc_df, city_df], ignore_index=True)\n",
    "all_df = all_df[all_df['non-std-address'].str.len() > 0]\n",
    "all_df.to_csv(\"addr_std_training_data_11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(popc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(statcan_df) + len(cpcdf) + len(pc_df) + len(popc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(pc_augment(\"l0r 01a\", letter_aug = 0.7, num_aug = 0.5))\n",
    "    # print(choice(conf_matrix.columns, p=conf_matrix.loc['0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [1,23]\n",
    "lst_2 = lst\n",
    "lst.append(4)\n",
    "print(lst_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
